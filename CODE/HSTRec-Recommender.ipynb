{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1ca25-f663-4542-8359-2b37c82daa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_embs = pd.read_csv(\"df_movie_embs.csv\")  \n",
    "\n",
    "df_ratings = pd.read_csv(\"ml-100k/u.data\", sep=\"\\t\", names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "df_ratings = df_ratings.drop(columns=[\"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3ed12-fc6f-43fa-b6b3-9e5d5cc0c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_avg_rating = df_ratings.groupby(\"movieId\")[\"rating\"].mean().reset_index()\n",
    "movie_avg_rating.columns = [\"movieId\", \"avg_rating\"]\n",
    "\n",
    "df_features = pd.merge(df_embs, movie_avg_rating, on=\"movieId\", how=\"left\")\n",
    "df_features = df_features.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da50ee-b590-4d66-8634-bd4b814a5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "emb_cols = [col for col in df_features.columns if col.startswith(\"emb_\")]\n",
    "k1 = 20  \n",
    "df_features[\"cluster_1\"] = KMeans(n_clusters=k1, random_state=42).fit_predict(df_features[emb_cols])\n",
    "\n",
    "df_features[\"cluster_2\"] = -1\n",
    "for c in range(k1):\n",
    "    subset = df_features[df_features[\"cluster_1\"] == c]\n",
    "    if len(subset) >= 2:\n",
    "        enhanced = subset[emb_cols + [\"avg_rating\"]]\n",
    "        df_features.loc[subset.index, \"cluster_2\"] = KMeans(n_clusters=min(5, len(subset)), random_state=42).fit_predict(enhanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d85a0-e730-48f8-94d4-948bd733b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features[\"final_cluster\"] = df_features[\"cluster_1\"].astype(str) + \"_\" + df_features[\"cluster_2\"].astype(str)\n",
    "movie_cluster_map = df_features.set_index(\"movieId\")[\"final_cluster\"].to_dict()\n",
    "\n",
    "df_ratings[\"cluster\"] = df_ratings[\"movieId\"].map(movie_cluster_map)\n",
    "df_ratings = df_ratings.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11688bc-b705-470c-b473-98980c52fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cluster_list = sorted(df_ratings[\"cluster\"].unique())\n",
    "cluster_to_idx = {c: i for i, c in enumerate(cluster_list)}\n",
    "\n",
    "user_vectors = defaultdict(lambda: np.zeros(len(cluster_list)))\n",
    "user_counts = defaultdict(lambda: np.zeros(len(cluster_list)))\n",
    "\n",
    "for _, row in df_ratings.iterrows():\n",
    "    uid = row[\"userId\"]\n",
    "    cid = row[\"cluster\"]\n",
    "    idx = cluster_to_idx[cid]\n",
    "    user_vectors[uid][idx] += row[\"rating\"]\n",
    "    user_counts[uid][idx] += 1\n",
    "\n",
    "user_features = {}\n",
    "for uid in user_vectors:\n",
    "    vec = user_vectors[uid]\n",
    "    count = user_counts[uid]\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        mean_vec = np.where(count != 0, vec / count, 0)\n",
    "    user_features[uid] = mean_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef384160-f1ad-4962-b91e-bfcb4c2dc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UserAttentionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, heads=4):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=heads, batch_first=True)\n",
    "        self.proj = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, user_matrix):\n",
    "        # user_matrix: (num_users, input_dim)\n",
    "        user_matrix = user_matrix.unsqueeze(1)  # (batch, seq_len=1, input_dim)\n",
    "        attn_output, _ = self.attn(user_matrix, user_matrix, user_matrix)  # self-attention\n",
    "        return self.proj(attn_output.squeeze(1))  # (batch, hidden_dim)\n",
    "\n",
    "user_ids = sorted(user_features.keys())\n",
    "user_matrix = torch.tensor([user_features[uid] for uid in user_ids], dtype=torch.float32)\n",
    "\n",
    "encoder = UserAttentionEncoder(input_dim=len(cluster_list))\n",
    "with torch.no_grad():\n",
    "    user_embeddings = encoder(user_matrix)  # (num_users, hidden_dim)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_sim_matrix = cosine_similarity(user_embeddings.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bb685-7cad-4568-bc54-cbd6cf4737e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_user, X_movie, y = [], [], []\n",
    "\n",
    "for _, row in df_ratings.iterrows():\n",
    "    uid, mid, rating = row[\"userId\"], row[\"movieId\"], row[\"rating\"]\n",
    "    if uid not in user_features:\n",
    "        continue\n",
    "    if mid not in df_features.set_index(\"movieId\").index:\n",
    "        continue\n",
    "\n",
    "    u_vec = user_features[uid]\n",
    "    m_vec = df_features[df_features[\"movieId\"] == mid][emb_cols + [\"avg_rating\"]].values[0]\n",
    "\n",
    "    X_user.append(u_vec)\n",
    "    X_movie.append(m_vec)\n",
    "    y.append(rating)\n",
    "\n",
    "X_user_tensor = torch.tensor(X_user, dtype=torch.float32).to(device)\n",
    "X_movie_tensor = torch.tensor(X_movie, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "user_dim = X_user_tensor.shape[1]\n",
    "movie_dim = X_movie_tensor.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d63aa8-2da7-4cb5-bcc5-90b149e6c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class TransformerRecommender(nn.Module):\n",
    "    def __init__(self, raw_user_dim, movie_dim, d_model=128, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pad_user = nn.Linear(raw_user_dim, d_model)   # 150 → 128\n",
    "        self.pad_movie = nn.Linear(movie_dim, d_model)     # 384 → 128\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 2, d_model))\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_vec, movie_vec):\n",
    "        u = self.pad_user(user_vec)     # (batch, d_model)\n",
    "        m = self.pad_movie(movie_vec)   # (batch, d_model)\n",
    "\n",
    "        x = torch.stack([u, m], dim=1)  # (batch, 2, d_model)\n",
    "\n",
    "        x = x + self.pos_embedding[:, :2, :]\n",
    "\n",
    "        encoded = self.encoder(x)  # (batch, 2, d_model)\n",
    "\n",
    "        combined = torch.cat([encoded[:, 0, :], encoded[:, 1, :]], dim=1)  # (batch, d_model*2)\n",
    "\n",
    "        return self.predictor(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04883cdb-c837-4302-87af-4a7bd92656bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_user_train, X_user_test, X_movie_train, X_movie_test, y_train, y_test = train_test_split(\n",
    "    X_user_tensor, X_movie_tensor, y_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_user_train, X_movie_train, y_train)\n",
    "test_dataset  = TensorDataset(X_user_test, X_movie_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e935623-69a0-41cc-ba39-be3625ffb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "sample_indices = np.random.choice(len(X_user_tensor), size=4000, replace=False)\n",
    "user_vectors_sample = X_user_tensor[sample_indices].cpu().numpy()\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(user_vectors_sample)\n",
    "\n",
    "user_pairs = []\n",
    "labels = []\n",
    "\n",
    "while len(user_pairs) < 3000:\n",
    "    i, j = random.sample(range(len(user_vectors_sample)), 2)\n",
    "    sim = cos_sim_matrix[i, j]\n",
    "    if sim > 0.95:\n",
    "        user_pairs.append((sample_indices[i], sample_indices[j]))\n",
    "        labels.append(1)\n",
    "    elif sim < 0.3:\n",
    "        user_pairs.append((sample_indices[i], sample_indices[j]))\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe9e65-9757-45a0-841c-452bf6445c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dim = X_user_tensor.shape[1]    \n",
    "movie_dim = X_movie_tensor.shape[1]  \n",
    "\n",
    "model = TransformerRecommender(user_dim, movie_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9712ece-2999-4c1c-ab58-9883dfe95640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosine_loss_fn = nn.CosineEmbeddingLoss(margin=0.3)\n",
    "lambda_sim = 0.5  \n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xu, xm, yt in train_loader:\n",
    "        xu, xm, yt = xu.to(device), xm.to(device), yt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(xu, xm)\n",
    "        mse_loss = loss_fn(preds, yt)\n",
    "\n",
    "        selected_pairs = random.sample(range(len(user_pairs)), 512)\n",
    "        u1_indices = [user_pairs[i][0] for i in selected_pairs]\n",
    "        u2_indices = [user_pairs[i][1] for i in selected_pairs]\n",
    "        sim_labels = torch.tensor([labels[i] for i in selected_pairs], dtype=torch.float32).to(device)\n",
    "\n",
    "        u1_vec = X_user_tensor[u1_indices].to(device)\n",
    "        u2_vec = X_user_tensor[u2_indices].to(device)\n",
    "        u1_emb = model.pad_user(u1_vec)\n",
    "        u2_emb = model.pad_user(u2_vec)\n",
    "        u1_out = model.encoder(u1_emb.unsqueeze(1) + model.pos_embedding[:, :1])\n",
    "        u2_out = model.encoder(u2_emb.unsqueeze(1) + model.pos_embedding[:, :1])\n",
    "        u1_final = u1_out.squeeze(1)\n",
    "        u2_final = u2_out.squeeze(1)\n",
    "\n",
    "        sim_loss = cosine_loss_fn(u1_final, u2_final, sim_labels)\n",
    "\n",
    "        loss = mse_loss + lambda_sim * sim_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\" Epoch {epoch+1}/30 - Total Hybrid Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c492d3f-5c5a-4978-afda-69a7d3281ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xu, xm, yt in test_loader:\n",
    "        xu, xm = xu.to(device), xm.to(device)\n",
    "        preds = model(xu, xm)\n",
    "        y_true.extend(yt.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\" MAE:  {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
